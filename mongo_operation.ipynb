{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "uri = \"mongodb+srv://Nidhish:Nidhish@coephackathon.pbuvv.mongodb.net/?retryWrites=true&w=majority&appName=CoepHackathon\"\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri)\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=client[\"mytestdb\"]\n",
    "collection=db[\"mytestcollection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertOneResult(ObjectId('6712a01b161d8b17e9235479'), acknowledged=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection.insert_one({\n",
    "#     \"repository\": \"Repo1\",\n",
    "#     \"code_snippet\": \"def authenticate_user(client_id, client_secret, authorization_code, redirect_uri):\\n    import requests\\n    \\n    # Define the token endpoint\\n    token_url = \\\"https://oauth2.example.com/token\\\"\\n    \\n    # Prepare the payload for the token request\\n    payload = {\\n        'client_id': client_id,\\n        'client_secret': client_secret,\\n        'code': authorization_code,\\n        'grant_type': 'authorization_code',\\n        'redirect_uri': redirect_uri\\n    }\\n    \\n    try:\\n        # Make a POST request to exchange the authorization code for an access token\\n        response = requests.post(token_url, data=payload)\\n        \\n        # Raise an exception if the request was unsuccessful\\n        response.raise_for_status()\\n        \\n        # Extract the access token from the response\\n        token_info = response.json()\\n        access_token = token_info.get('access_token')\\n        \\n        return access_token  # Return the access token for authenticated requests\\n    \\n    except requests.exceptions.RequestException as e:\\n        print(f\\\"Error during authentication: {e}\\\")\\n        return None  # Return None if authentication fails\",\n",
    "#     \"fullplot\": \"OAuth-based user authentication following company security practices\",\n",
    "#     \"tags\": [\"Python\", \"OAuth\", \"Authentication\", \"Security\"]\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertOneResult(ObjectId('67117ba36e9b685ab350b384'), acknowledged=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection.insert_one({\n",
    "#     \"repository\": \"Repo2\",\n",
    "#     \"file_path\": \"/src/api/endpoints.py\",\n",
    "#     \"code_snippet\": \"from flask import Flask, jsonify\\n\\napp = Flask(__name__)\\n\\n@app.route('/api/data', methods=['GET'])\\ndef get_data():\\n    data = {'key': 'value'}\\n    return jsonify(data)\",\n",
    "#     \"fullplot\": \"A simple Flask API endpoint that returns JSON data\",\n",
    "#     \"tags\": [\"Python\", \"Flask\", \"API\", \"Web\"]\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertOneResult(ObjectId('67117c2c6e9b685ab350b385'), acknowledged=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection.insert_one({\n",
    "#      \"repository\": \"Repo3\",\n",
    "#     \"file_path\": \"/src/ml/model.py\",\n",
    "#     \"code_snippet\": \"from sklearn.ensemble import RandomForestClassifier\\n\\ndef train_model(X, y):\\n    model = RandomForestClassifier()\\n    model.fit(X, y)\\n    return model\",\n",
    "#     \"fullplot\": \"Train a Random Forest model using scikit-learn\",\n",
    "#     \"tags\": [\"Python\", \"Machine Learning\", \"Scikit-learn\", \"Model\"],\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodingStuff\\COEP_HACKATHON\\myenv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"f68b6c67-0cfd-47b3-980b-5c29ea360fbf\")\n",
    "index = pc.Index(\"mongo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def get_result(query,similar_result=1):\n",
    "  embedding=embedding_model.encode(query)\n",
    "  embedding=embedding.tolist()\n",
    "\n",
    "  result=index.query(\n",
    "    vector=embedding,\n",
    "    top_k=similar_result,\n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query=\"what is the simple flask that run on json?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result=get_result(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '67117ba36e9b685ab350b384',\n",
       "              'score': 0.737647891,\n",
       "              'values': []},\n",
       "             {'id': '67117c9a6e9b685ab350b386',\n",
       "              'score': 0.0914500281,\n",
       "              'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.objectid import ObjectId\n",
    "\n",
    "\n",
    "mylist=[]\n",
    "for i in  range(len(result[\"matches\"])):\n",
    "  value=result[\"matches\"][i]['id']\n",
    "  mylist.append(collection.find_one({\"_id\": ObjectId(value)}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('67117ba36e9b685ab350b384'),\n",
       "  'repository': 'Repo2',\n",
       "  'file_path': '/src/api/endpoints.py',\n",
       "  'code_snippet': \"from flask import Flask, jsonify\\n\\napp = Flask(__name__)\\n\\n@app.route('/api/data', methods=['GET'])\\ndef get_data():\\n    data = {'key': 'value'}\\n    return jsonify(data)\",\n",
       "  'fullplot': 'A simple Flask API endpoint that returns JSON data',\n",
       "  'tags': ['Python', 'Flask', 'API', 'Web']}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code snippet: from flask import Flask, jsonify\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "@app.route('/api/data', methods=['GET'])\n",
      "def get_data():\n",
      "    data = {'key': 'value'}\n",
      "    return jsonify(data), Full plot: A simple Flask API endpoint that returns JSON data, File path: /src/api/endpoints.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_information = \"\"\n",
    "for i in range(len(mylist)):\n",
    "    fullplot = mylist[i][\"fullplot\"]\n",
    "    title = mylist[i][\"code_snippet\"]\n",
    "    \n",
    "    # Check if 'file_path' exists in the current dictionary\n",
    "    file_paths = mylist[i].get(\"file_path\", \"No file path available\")\n",
    "    \n",
    "    combined_information += f\"Code snippet: {title}, Full plot: {fullplot}, File path: {file_paths}\\n\"\n",
    "\n",
    "print(combined_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    f\"You are a helpful coding assistant that supports new developers in finding code snippets. \"\n",
    "    f\"When responding, make sure to follow the company's custom technical instructions and practices.\\n\"\n",
    "    f\"User Query: {query}\\n\"\n",
    "    f\"Here are relevant code implementations from various source code repositories:\\n\"\n",
    "    f\"{combined_information}\\n\"\n",
    "    f\"Please provide a concise and clear response, including the most relevant code snippets and explanations that adhere to the specified guidelines.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful coding assistant that supports new developers in finding code snippets. When responding, make sure to follow the company's custom technical instructions and practices.\n",
      "User Query: what is the simple flask that run on json?\n",
      "Here are relevant code implementations from various source code repositories:\n",
      "Code snippet: from flask import Flask, jsonify\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "@app.route('/api/data', methods=['GET'])\n",
      "def get_data():\n",
      "    data = {'key': 'value'}\n",
      "    return jsonify(data), Full plot: A simple Flask API endpoint that returns JSON data, File path: /src/api/endpoints.py\n",
      "\n",
      "Please provide a concise and clear response, including the most relevant code snippets and explanations that adhere to the specified guidelines.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "groq_chat = ChatGroq(groq_api_key=os.getenv('GROQ_API_KEY'), model_name='mixtral-8x7b-32768')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To create a simple Flask application that runs on JSON, you can use the `flask` and `jsonify` modules. Here's an example of a Flask application that returns JSON data when a GET request is made to the `/api/data` endpoint:\\n```python\\nfrom flask import Flask, jsonify\\n\\napp = Flask(__name__)\\n\\n@app.route('/api/data', methods=['GET'])\\ndef get_data():\\n    data = {'key': 'value'}\\n    return jsonify(data)\\n```\\nIn this code snippet, we first import the necessary modules. Then, we create a new Flask application and define a route for the `/api/data` endpoint that accepts GET requests. Within the route handler function, we create a dictionary containing some data, and then use the `jsonify` function to convert the dictionary to a JSON response.\\n\\nThis simple Flask application can be run by saving the code to a file (e.g. `app.py`) and then executing the following command in the terminal:\\n```\\nflask run\\n```\\nBy default, the application will be accessible at `http://localhost:5000/`. To access the JSON data, navigate to `http://localhost:5000/api/data` in your web browser or use a tool like `curl` or Postman to make a GET request to the endpoint.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 313, 'prompt_tokens': 191, 'total_tokens': 504, 'completion_time': 0.508819163, 'prompt_time': 0.012458118, 'queue_time': 0.0028117019999999993, 'total_time': 0.521277281}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-563bd744-f4f0-44f2-b049-fc22251590f2-0', usage_metadata={'input_tokens': 191, 'output_tokens': 313, 'total_tokens': 504})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = groq_chat.invoke(prompt)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('6712a0698566b1319aed134d'), 'repository': 'test-repo-utilitysearch', 'file_path': 'testdir\\\\Clonedrepo\\\\quizDom.py', 'code_snippet': 'from flask import Flask, request, jsonify\\r\\nfrom educhain import Educhain\\r\\nfrom educhain.core import config\\r\\nfrom langchain.chat_models import ChatOpenAI\\r\\nfrom dotenv import load_dotenv\\r\\nimport os\\r\\n\\r\\n# Load environment variables\\r\\nload_dotenv()\\r\\n\\r\\n# Replace with your OpenAI API credentials\\r\\ncustom_template = \"\"\"\\r\\nGenerate {num} multiple-choice question (MCQ) based on the given topic and level.\\r\\nProvide the question, four answer options, and the correct answer.\\r\\nTopic: {topic}\\r\\nLearning Objective: {learning_objective}\\r\\nDifficulty Level: {difficulty_level}\\r\\n\"\"\"\\r\\n\\r\\nllama = ChatOpenAI(\\r\\n    model=\"llama-3.1-70b-versatile\",\\r\\n    openai_api_base=\"https://api.groq.com/openai/v1\",\\r\\n    openai_api_key=os.getenv(\\'GROQ_API_KEY\\')  # Replace with your actual key\\r\\n)\\r\\n\\r\\nllm_config = config.LLMConfig(\\r\\n    custom_model=llama\\r\\n)\\r\\n\\r\\nclient = Educhain(llm_config)\\r\\n\\r\\napp = Flask(__name__)\\r\\nprint(\"test\")\\r\\nprint(\"test\")\\r\\nprint(\"test\")\\r\\n\\r\\n@app.route(\"/generate_questions\", methods=[\"POST\"])\\r\\ndef generate_questions():\\r\\n    if request.method == \"POST\":\\r\\n        data = request.get_json(force=True)  # Get data from the request body\\r\\n\\r\\n        topic = data.get(\"topic\")\\r\\n        num = data.get(\"num\")\\r\\n        learning_objective = data.get(\"learning_objective\")\\r\\n        difficulty_level = data.get(\"difficulty_level\")\\r\\n\\r\\n        if not all([topic, num, learning_objective, difficulty_level]):\\r\\n            return jsonify({\"error\": \"Missing required parameters\"}), 400\\r\\n\\r\\n        try:\\r\\n            result = client.qna_engine.generate_questions(\\r\\n                topic=topic, num=num, learning_objective=learning_objective, difficulty_level=difficulty_level, prompt_template=custom_template\\r\\n            )\\r\\n            return jsonify(result.json())\\r\\n        except Exception as e:\\r\\n            return jsonify({\"error\": str(e)}), 500\\r\\n\\r\\n    return jsonify({\"error\": \"Invalid request method\"}), 405\\r\\n\\r\\n\\r\\nif __name__ == \"__main__\":\\r\\n    app.run(debug=True)', 'fullplot': 'This code sets up a Flask web server that uses the Educhain library and OpenAI\\'s API to generate multiple-choice questions based on a given topic, learning objective, and difficulty level, which are sent as JSON in a POST request to the \"/generate\\\\_questions\" endpoint.', 'tags': 'Here are some technical tags for the provided code:\\n\\n* Flask (web framework for building APIs in Python)\\n* Educhain (an educational blockchain platform)\\n* ChatOpenAI (a chat model from Langchain)\\n* config (a module for configuring the LLM)\\n* requests (for making HTTP requests)\\n* jsonify (for converting Python objects to JSON)\\n* Python environment variables\\n* OpenAI API (for accessing language model capabilities)\\n* Groq API (for accessing the Groq API, which is used as a base for the OpenAI API)\\n* Exception handling (for managing errors that occur in the code)\\n* RESTful API design (for creating an API endpoint to generate questions)\\n* API security (for managing API credentials using environment variables)\\n* Prompt engineering (for customizing the prompt used to generate questions)\\n\\nI hope this helps! Let me know if you have any other questions.'}]\n",
      "Code snippet: from flask import Flask, request, jsonify\n",
      "from educhain import Educhain\n",
      "from educhain.core import config\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from dotenv import load_dotenv\n",
      "import os\n",
      "\n",
      "# Load environment variables\n",
      "load_dotenv()\n",
      "\n",
      "# Replace with your OpenAI API credentials\n",
      "custom_template = \"\"\"\n",
      "Generate {num} multiple-choice question (MCQ) based on the given topic and level.\n",
      "Provide the question, four answer options, and the correct answer.\n",
      "Topic: {topic}\n",
      "Learning Objective: {learning_objective}\n",
      "Difficulty Level: {difficulty_level}\n",
      "\"\"\"\n",
      "\n",
      "llama = ChatOpenAI(\n",
      "    model=\"llama-3.1-70b-versatile\",\n",
      "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
      "    openai_api_key=os.getenv('GROQ_API_KEY')  # Replace with your actual key\n",
      ")\n",
      "\n",
      "llm_config = config.LLMConfig(\n",
      "    custom_model=llama\n",
      ")\n",
      "\n",
      "client = Educhain(llm_config)\n",
      "\n",
      "app = Flask(__name__)\n",
      "print(\"test\")\n",
      "print(\"test\")\n",
      "print(\"test\")\n",
      "\n",
      "@app.route(\"/generate_questions\", methods=[\"POST\"])\n",
      "def generate_questions():\n",
      "    if request.method == \"POST\":\n",
      "        data = request.get_json(force=True)  # Get data from the request body\n",
      "\n",
      "        topic = data.get(\"topic\")\n",
      "        num = data.get(\"num\")\n",
      "        learning_objective = data.get(\"learning_objective\")\n",
      "        difficulty_level = data.get(\"difficulty_level\")\n",
      "\n",
      "        if not all([topic, num, learning_objective, difficulty_level]):\n",
      "            return jsonify({\"error\": \"Missing required parameters\"}), 400\n",
      "\n",
      "        try:\n",
      "            result = client.qna_engine.generate_questions(\n",
      "                topic=topic, num=num, learning_objective=learning_objective, difficulty_level=difficulty_level, prompt_template=custom_template\n",
      "            )\n",
      "            return jsonify(result.json())\n",
      "        except Exception as e:\n",
      "            return jsonify({\"error\": str(e)}), 500\n",
      "\n",
      "    return jsonify({\"error\": \"Invalid request method\"}), 405\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    app.run(debug=True), Full plot: This code sets up a Flask web server that uses the Educhain library and OpenAI's API to generate multiple-choice questions based on a given topic, learning objective, and difficulty level, which are sent as JSON in a POST request to the \"/generate\\_questions\" endpoint., File path: testdir\\Clonedrepo\\quizDom.py\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'from flask import Flask, request, jsonify\\r\\nfrom educhain import Educhain\\r\\nfrom educhain.core import config\\r\\nfrom langchain.chat_models import ChatOpenAI\\r\\nfrom dotenv import load_dotenv\\r\\nimport os\\r\\n\\r\\n# Load environment variables\\r\\nload_dotenv()\\r\\n\\r\\n# Replace with your OpenAI API credentials\\r\\ncustom_template = \"\"\"\\r\\nGenerate {num} multiple-choice question (MCQ) based on the given topic and level.\\r\\nProvide the question, four answer options, and the correct answer.\\r\\nTopic: {topic}\\r\\nLearning Objective: {learning_objective}\\r\\nDifficulty Level: {difficulty_level}\\r\\n\"\"\"\\r\\n\\r\\nllama = ChatOpenAI(\\r\\n    model=\"llama-3.1-70b-versatile\",\\r\\n    openai_api_base=\"https://api.groq.com/openai/v1\",\\r\\n    openai_api_key=os.getenv(\\'GROQ_API_KEY\\')  # Replace with your actual key\\r\\n)\\r\\n\\r\\nllm_config = config.LLMConfig(\\r\\n    custom_model=llama\\r\\n)\\r\\n\\r\\nclient = Educhain(llm_config)\\r\\n\\r\\napp = Flask(__name__)\\r\\nprint(\"test\")\\r\\nprint(\"test\")\\r\\nprint(\"test\")\\r\\n\\r\\n@app.route(\"/generate_questions\", methods=[\"POST\"])\\r\\ndef generate_questions():\\r\\n    if request.method == \"POST\":\\r\\n        data = request.get_json(force=True)  # Get data from the request body\\r\\n\\r\\n        topic = data.get(\"topic\")\\r\\n        num = data.get(\"num\")\\r\\n        learning_objective = data.get(\"learning_objective\")\\r\\n        difficulty_level = data.get(\"difficulty_level\")\\r\\n\\r\\n        if not all([topic, num, learning_objective, difficulty_level]):\\r\\n            return jsonify({\"error\": \"Missing required parameters\"}), 400\\r\\n\\r\\n        try:\\r\\n            result = client.qna_engine.generate_questions(\\r\\n                topic=topic, num=num, learning_objective=learning_objective, difficulty_level=difficulty_level, prompt_template=custom_template\\r\\n            )\\r\\n            return jsonify(result.json())\\r\\n        except Exception as e:\\r\\n            return jsonify({\"error\": str(e)}), 500\\r\\n\\r\\n    return jsonify({\"error\": \"Invalid request method\"}), 405\\r\\n\\r\\n\\r\\nif __name__ == \"__main__\":\\r\\n    app.run(debug=True)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \" code of flask to generate multiple choice questions using langchain and educhain \"\n",
    "result=get_result(query)\n",
    "mylist=[]\n",
    "for i in  range(len(result[\"matches\"])):\n",
    "  value=result[\"matches\"][i]['id']\n",
    "  mylist.append(collection.find_one({\"_id\": ObjectId(value)}))\n",
    "  \n",
    "\n",
    "print(mylist)\n",
    "combined_information = \"\"\n",
    "for i in range(len(mylist)):\n",
    "    fullplot = mylist[i][\"fullplot\"]\n",
    "    title = mylist[i][\"code_snippet\"]\n",
    "    \n",
    "    # Check if 'file_path' exists in the current dictionary\n",
    "    file_paths = mylist[i].get(\"file_path\", \"No file path available\")\n",
    "    \n",
    "    combined_information += f\"Code snippet: {title}, Full plot: {fullplot}, File path: {file_paths}\\n\"\n",
    "\n",
    "print(combined_information)\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code snippet: from flask import Flask, request, jsonify\n",
      "from educhain import Educhain\n",
      "from educhain.core import config\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from dotenv import load_dotenv\n",
      "import os\n",
      "\n",
      "# Load environment variables\n",
      "load_dotenv()\n",
      "\n",
      "# Replace with your OpenAI API credentials\n",
      "custom_instructions = \"Include real-world examples\"  # Predefined instruction\n",
      "\n",
      "llama = ChatOpenAI(\n",
      "    model=\"llama-3.1-70b-versatile\",\n",
      "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
      "    openai_api_key=os.getenv('GROQ_API_KEY')  # Replace with your actual key\n",
      ")\n",
      "\n",
      "llm_config = config.LLMConfig(\n",
      "    custom_model=llama\n",
      ")\n",
      "\n",
      "client = Educhain(llm_config)\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "\n",
      "@app.route(\"/generate_lesson_plan\", methods=[\"POST\"])\n",
      "def generate_lesson_plan():\n",
      "    if request.method == \"POST\":\n",
      "        data = request.get_json(force=True)  # Get data from the request body\n",
      "\n",
      "        topic = data.get(\"topic\")\n",
      "\n",
      "        if not topic:\n",
      "            return jsonify({\"error\": \"Missing required parameter: topic\"}), 400\n",
      "\n",
      "        try:\n",
      "            lesson_plan = client.content_engine.generate_lesson_plan(\n",
      "                topic=topic, custom_instructions=custom_instructions\n",
      "            )\n",
      "            return jsonify(lesson_plan.json())\n",
      "        except Exception as e:\n",
      "            return jsonify({\"error\": str(e)}), 500\n",
      "\n",
      "    return jsonify({\"error\": \"Invalid request method\"}), 405\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    app.run(debug=True) , Full plot: This is a Flask application that utilizes the Educhain and Langchain libraries to generate a lesson plan based on a given topic, with an option to include real-world examples, when a POST request is made to the /generate_lesson_plan endpoint., File path: Cloned_repo\\lessonPlan.py\n",
      "Technical Guidelines: Ensure that Flask applications follow the company's security best practices, including proper session management and request validation.\n",
      "Use predefined Langchain libraries and always ensure proper chaining of the modules.\n",
      "When working with Educhain, verify that all educational data conforms to the latest compliance standards.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bson import ObjectId\n",
    "\n",
    "# Example set of technical guidelines (this would be expanded based on your real guidelines)\n",
    "TECHNICAL_GUIDELINES = {\n",
    "    \"Flask\": \"Ensure that Flask applications follow the company's security best practices, including proper session management and request validation.\",\n",
    "    \"Langchain\": \"Use predefined Langchain libraries and always ensure proper chaining of the modules.\",\n",
    "    \"Educhain\": \"When working with Educhain, verify that all educational data conforms to the latest compliance standards.\",\n",
    "    # Add more guidelines as needed\n",
    "}\n",
    "\n",
    "# Function to get relevant technical guidelines based on title and fullplot\n",
    "def get_technical_guidelines(title, fullplot):\n",
    "    guidelines = []\n",
    "    \n",
    "    # Check if title or fullplot contains keywords related to the technical guidelines\n",
    "    for keyword, guideline in TECHNICAL_GUIDELINES.items():\n",
    "        if keyword in title or keyword in fullplot:\n",
    "            guidelines.append(guideline)\n",
    "    \n",
    "    if guidelines:\n",
    "        return \"\\n\".join(guidelines)\n",
    "    else:\n",
    "        return \"No specific technical guidelines found.\"\n",
    "\n",
    "# Query results from the database\n",
    "query = \"Flask application that utilizes the Educhain and Langchain libraries to generate a lesson plan\"\n",
    "result = get_result(query)\n",
    "\n",
    "# Extract the matched documents based on IDs\n",
    "mylist = []\n",
    "for i in range(len(result[\"matches\"])):\n",
    "    value = result[\"matches\"][i]['id']\n",
    "    mylist.append(collection.find_one({\"_id\": ObjectId(value)}))\n",
    "\n",
    "# Combine information and retrieve technical guidelines\n",
    "combined_information = \"\"\n",
    "for i in range(len(mylist)):\n",
    "    fullplot = mylist[i][\"fullplot\"]\n",
    "    title = mylist[i][\"code_snippet\"]\n",
    "\n",
    "    # Check if 'file_path' exists in the current dictionary\n",
    "    file_paths = mylist[i].get(\"file_path\", \"No file path available\")\n",
    "    \n",
    "    # Retrieve technical guidelines based on title and fullplot\n",
    "    guidelines = get_technical_guidelines(title, fullplot)\n",
    "    \n",
    "    combined_information += f\"Code snippet: {title}, Full plot: {fullplot}, File path: {file_paths}\\nTechnical Guidelines: {guidelines}\\n\\n\"\n",
    "\n",
    "print(combined_information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
